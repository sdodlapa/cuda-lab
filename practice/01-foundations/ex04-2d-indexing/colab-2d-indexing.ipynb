{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9f7695c",
   "metadata": {},
   "source": [
    "# Exercise 04: 2D Grid Indexing ğŸ“Š\n",
    "\n",
    "Work with 2D data (images, matrices) using 2D thread grids!\n",
    "\n",
    "## Learning Goals\n",
    "- Use `dim3` for 2D block and grid dimensions\n",
    "- Calculate 2D thread indices (row, col)\n",
    "- Understand row-major memory layout\n",
    "- Process matrices in parallel\n",
    "\n",
    "## ğŸš€ Setup\n",
    "\n",
    "**Enable GPU**: Runtime â†’ Change runtime type â†’ T4 GPU â†’ Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bfd287",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi --query-gpu=name --format=csv,noheader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06954302",
   "metadata": {},
   "source": [
    "## ğŸ“š Key Concepts\n",
    "\n",
    "### 2D Launch Configuration with dim3\n",
    "```cpp\n",
    "dim3 threadsPerBlock(16, 16);  // 16x16 = 256 threads\n",
    "dim3 blocksPerGrid(\n",
    "    (width + 15) / 16,   // Columns (x)\n",
    "    (height + 15) / 16   // Rows (y)\n",
    ");\n",
    "kernel<<<blocksPerGrid, threadsPerBlock>>>(...);\n",
    "```\n",
    "\n",
    "### 2D Thread Indexing\n",
    "```cpp\n",
    "int col = blockIdx.x * blockDim.x + threadIdx.x;  // X â†’ column\n",
    "int row = blockIdx.y * blockDim.y + threadIdx.y;  // Y â†’ row\n",
    "```\n",
    "\n",
    "### Row-Major Memory Layout\n",
    "```\n",
    "Matrix A[3][4]:           Stored in 1D memory:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        \n",
    "â”‚ 0  1  2  3 â”‚ Row 0     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "â”‚ 4  5  6  7 â”‚ Row 1      â†‘           â†‘           â†‘\n",
    "â”‚ 8  9 10 11 â”‚ Row 2      Row 0       Row 1       Row 2\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "index = row * width + col\n",
    "Example: A[1][2] â†’ 1 * 4 + 2 = 6\n",
    "```\n",
    "\n",
    "### Visual: Thread to Matrix Mapping\n",
    "```\n",
    "Matrix 64x48        Grid of Blocks (4x3)     Each Block (16x16)\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚             â”‚     â”‚00â”‚10â”‚20â”‚30â”‚           â”‚T(0,0)  ...T(15,0)â”‚\n",
    "â”‚   64 cols   â”‚  â†’  â”œâ”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â”€â”€â”¤     â†’     â”‚  ...      ...   â”‚\n",
    "â”‚   48 rows   â”‚     â”‚01â”‚11â”‚21â”‚31â”‚           â”‚T(0,15)...T(15,15)â”‚\n",
    "â”‚             â”‚     â”œâ”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â”€â”€â”¤           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚02â”‚12â”‚22â”‚32â”‚               256 threads\n",
    "                    â””â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb87bca",
   "metadata": {},
   "source": [
    "## Step 1: Complete the Exercise\n",
    "\n",
    "Scale every element in a matrix: `output[row][col] = input[row][col] * scalar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b05487",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile grid_2d.cu\n",
    "/**\n",
    " * Exercise 04: 2D Grid Indexing\n",
    " */\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define CUDA_CHECK(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(err)); \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "// 2D kernel: scale each matrix element\n",
    "__global__ void matrixScale(float *input, float *output, \n",
    "                            float scalar, int width, int height) {\n",
    "    // Calculate 2D indices\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;  // X â†’ column\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;  // Y â†’ row\n",
    "    \n",
    "    // Bounds check (essential for partial blocks at edges!)\n",
    "    if (col < width && row < height) {\n",
    "        // Convert 2D to 1D index (row-major)\n",
    "        int index = row * width + col;\n",
    "        output[index] = input[index] * scalar;\n",
    "    }\n",
    "}\n",
    "\n",
    "void printMatrix(float *m, int w, int h, const char *name) {\n",
    "    printf(\"%s (showing 5x5 corner):\\n\", name);\n",
    "    for (int r = 0; r < 5 && r < h; r++) {\n",
    "        for (int c = 0; c < 5 && c < w; c++)\n",
    "            printf(\"%5.1f \", m[r * w + c]);\n",
    "        printf(\"...\\n\");\n",
    "    }\n",
    "    printf(\"...\\n\\n\");\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int width = 1024;\n",
    "    int height = 768;\n",
    "    float scalar = 2.5f;\n",
    "    size_t size = width * height * sizeof(float);\n",
    "    \n",
    "    printf(\"Matrix: %d x %d, Scalar: %.1f\\n\", width, height, scalar);\n",
    "    printf(\"Total elements: %d (%.2f MB)\\n\\n\", width * height, size/1e6);\n",
    "    \n",
    "    // Host memory\n",
    "    float *h_in = (float*)malloc(size);\n",
    "    float *h_out = (float*)malloc(size);\n",
    "    \n",
    "    // Initialize\n",
    "    for (int i = 0; i < width * height; i++)\n",
    "        h_in[i] = (float)(i % 10);\n",
    "    \n",
    "    printMatrix(h_in, width, height, \"Input\");\n",
    "    \n",
    "    // Device memory\n",
    "    float *d_in, *d_out;\n",
    "    CUDA_CHECK(cudaMalloc(&d_in, size));\n",
    "    CUDA_CHECK(cudaMalloc(&d_out, size));\n",
    "    CUDA_CHECK(cudaMemcpy(d_in, h_in, size, cudaMemcpyHostToDevice));\n",
    "    \n",
    "    // 2D launch configuration\n",
    "    dim3 threads(16, 16);  // 256 threads per block\n",
    "    dim3 blocks(\n",
    "        (width + threads.x - 1) / threads.x,\n",
    "        (height + threads.y - 1) / threads.y\n",
    "    );\n",
    "    \n",
    "    printf(\"Grid: %d x %d blocks\\n\", blocks.x, blocks.y);\n",
    "    printf(\"Threads per block: %d x %d = %d\\n\", threads.x, threads.y, threads.x*threads.y);\n",
    "    printf(\"Total threads: %d\\n\\n\", blocks.x * blocks.y * threads.x * threads.y);\n",
    "    \n",
    "    // Launch kernel\n",
    "    matrixScale<<<blocks, threads>>>(d_in, d_out, scalar, width, height);\n",
    "    CUDA_CHECK(cudaGetLastError());\n",
    "    CUDA_CHECK(cudaDeviceSynchronize());\n",
    "    \n",
    "    // Copy back\n",
    "    CUDA_CHECK(cudaMemcpy(h_out, d_out, size, cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    printMatrix(h_out, width, height, \"Output\");\n",
    "    \n",
    "    // Verify\n",
    "    bool ok = true;\n",
    "    for (int i = 0; i < width * height && ok; i++)\n",
    "        if (fabsf(h_out[i] - h_in[i] * scalar) > 0.001f) ok = false;\n",
    "    \n",
    "    printf(\"%s\\n\", ok ? \"âœ… PASSED!\" : \"âŒ FAILED!\");\n",
    "    \n",
    "    CUDA_CHECK(cudaFree(d_in));\n",
    "    CUDA_CHECK(cudaFree(d_out));\n",
    "    free(h_in); free(h_out);\n",
    "    \n",
    "    return ok ? 0 : 1;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e603539",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc grid_2d.cu -o grid_2d && ./grid_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30378c07",
   "metadata": {},
   "source": [
    "## ğŸ§ª Experiment: Matrix Transpose\n",
    "\n",
    "A more interesting 2D operation - swap rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile transpose.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Transpose: output[col][row] = input[row][col]\n",
    "__global__ void transpose(float *in, float *out, int width, int height) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (col < width && row < height) {\n",
    "        int in_idx = row * width + col;       // Input:  [row][col]\n",
    "        int out_idx = col * height + row;     // Output: [col][row]\n",
    "        out[out_idx] = in[in_idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "void printMatrix(float *m, int w, int h, const char *name) {\n",
    "    printf(\"%s (%dx%d):\\n\", name, w, h);\n",
    "    for (int r = 0; r < h; r++) {\n",
    "        for (int c = 0; c < w; c++)\n",
    "            printf(\"%4.0f \", m[r * w + c]);\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int W = 4, H = 3;  // Small for visualization\n",
    "    size_t size_in = W * H * sizeof(float);\n",
    "    size_t size_out = H * W * sizeof(float);  // Transposed dimensions\n",
    "    \n",
    "    float *h_in = (float*)malloc(size_in);\n",
    "    float *h_out = (float*)malloc(size_out);\n",
    "    \n",
    "    // Fill with identifiable values\n",
    "    for (int r = 0; r < H; r++)\n",
    "        for (int c = 0; c < W; c++)\n",
    "            h_in[r * W + c] = r * 10 + c;  // e.g., 00, 01, 02, 03, 10, 11...\n",
    "    \n",
    "    printMatrix(h_in, W, H, \"Input\");\n",
    "    \n",
    "    float *d_in, *d_out;\n",
    "    cudaMalloc(&d_in, size_in);\n",
    "    cudaMalloc(&d_out, size_out);\n",
    "    cudaMemcpy(d_in, h_in, size_in, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    dim3 threads(16, 16);\n",
    "    dim3 blocks((W + 15) / 16, (H + 15) / 16);\n",
    "    transpose<<<blocks, threads>>>(d_in, d_out, W, H);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaMemcpy(h_out, d_out, size_out, cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // Note: transposed dimensions are (H x W)\n",
    "    printMatrix(h_out, H, W, \"Transposed\");\n",
    "    \n",
    "    printf(\"Notice: rows became columns, columns became rows!\\n\");\n",
    "    \n",
    "    cudaFree(d_in); cudaFree(d_out);\n",
    "    free(h_in); free(h_out);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c693189",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc transpose.cu -o transpose && ./transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae769b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”„ Python Comparison (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numba -q\n",
    "\n",
    "from numba import cuda\n",
    "import numpy as np\n",
    "\n",
    "@cuda.jit\n",
    "def matrix_scale_python(input, output, scalar):\n",
    "    col, row = cuda.grid(2)  # 2D grid! Returns (x, y) tuple\n",
    "    \n",
    "    if row < input.shape[0] and col < input.shape[1]:\n",
    "        output[row, col] = input[row, col] * scalar\n",
    "\n",
    "# Test\n",
    "height, width = 768, 1024\n",
    "h_input = np.arange(height * width, dtype=np.float32).reshape(height, width) % 10\n",
    "h_output = np.zeros_like(h_input)\n",
    "\n",
    "d_input = cuda.to_device(h_input)\n",
    "d_output = cuda.to_device(h_output)\n",
    "\n",
    "# 2D configuration\n",
    "threads = (16, 16)\n",
    "blocks = ((width + 15) // 16, (height + 15) // 16)\n",
    "\n",
    "matrix_scale_python[blocks, threads](d_input, d_output, 2.5)\n",
    "\n",
    "result = d_output.copy_to_host()\n",
    "print(\"Corner of result:\")\n",
    "print(result[:3, :5])\n",
    "print(f\"\\nâœ… Correct? {np.allclose(result, h_input * 2.5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b37928",
   "metadata": {},
   "source": [
    "### C++ vs Python: 2D Indexing\n",
    "\n",
    "| C++ | Python (Numba) |\n",
    "|-----|----------------|\n",
    "| `dim3 threads(16, 16)` | `threads = (16, 16)` |\n",
    "| `dim3 blocks(x, y)` | `blocks = (x, y)` |\n",
    "| `blockIdx.x * blockDim.x + threadIdx.x` | `cuda.grid(2)` returns tuple |\n",
    "| Manual row-major indexing | NumPy 2D array indexing |\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Summary\n",
    "\n",
    "You learned:\n",
    "- **dim3** for 2D block/grid dimensions\n",
    "- **col (x)** and **row (y)** from thread indices\n",
    "- **Row-major layout**: `index = row * width + col`\n",
    "- **Bounds checking** is essential for edge blocks\n",
    "\n",
    "## â¡ï¸ Next Steps\n",
    "\n",
    "Continue with:\n",
    "- [Day 2: Thread Indexing Notebook](../../../learning-path/week-01/day-2-thread-indexing.ipynb) - More patterns\n",
    "- [Day 3: Memory Basics](../../../learning-path/week-01/day-3-memory-basics.ipynb) - Memory transfers"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

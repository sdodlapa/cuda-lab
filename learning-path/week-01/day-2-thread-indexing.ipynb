{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ddfa01",
   "metadata": {},
   "source": [
    "# ğŸš€ Day 2: Thread Indexing Mastery\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sdodlapa/cuda-lab/blob/main/learning-path/week-01/day-2-thread-indexing.ipynb)\n",
    "\n",
    "> **Note:** If running on Google Colab, go to `Runtime â†’ Change runtime type â†’ T4 GPU` before starting!\n",
    "\n",
    "## ğŸ“‹ This Notebook Structure\n",
    "\n",
    "| Section | Language | Purpose |\n",
    "|---------|----------|---------|\n",
    "| **Part 1** | ğŸ”· **CUDA C++** | Primary - Industry standard |\n",
    "| **Part 2** | ğŸ Python (Numba) | Optional - Quick prototyping |\n",
    "\n",
    "**Focus on Part 1 (CUDA C++)** - Python section is for reference only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22972faa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: CUDA C++ (Primary) ğŸ”·\n",
    "\n",
    "## Verify CUDA Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c765cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify CUDA is available\n",
    "!nvcc --version\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "!nvidia-smi --query-gpu=name,memory.total,compute_cap --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71469805",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "Today you'll master **thread indexing** - how each thread knows which data element to process.\n",
    "\n",
    "- Understand 1D, 2D, and 3D thread indexing\n",
    "- Master the relationship between blocks, threads, and global indices\n",
    "- Implement grid-stride loops for handling any array size\n",
    "- Apply indexing to real 2D problems (matrices, images)\n",
    "\n",
    "## Thread Hierarchy\n",
    "\n",
    "```\n",
    "                           GRID\n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚ Block   Block   Block   â”‚\n",
    "                â”‚ (0,0)   (1,0)   (2,0)   â”‚\n",
    "                â”‚                         â”‚\n",
    "                â”‚ Block   Block   Block   â”‚\n",
    "                â”‚ (0,1)   (1,1)   (2,1)   â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        \n",
    "                      Each Block:\n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚ Thread Thread Thread    â”‚\n",
    "                â”‚ (0,0)  (1,0)  (2,0)     â”‚\n",
    "                â”‚                         â”‚\n",
    "                â”‚ Thread Thread Thread    â”‚\n",
    "                â”‚ (0,1)  (1,1)  (2,1)     â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**CUDA C++ Built-in Variables:**\n",
    "- `threadIdx.x/y/z` - Thread index within block\n",
    "- `blockIdx.x/y/z` - Block index within grid  \n",
    "- `blockDim.x/y/z` - Threads per block\n",
    "- `gridDim.x/y/z` - Blocks in grid\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 1D Indexing: The Foundation\n",
    "\n",
    "For 1D arrays, each thread needs a unique **global index**:\n",
    "\n",
    "```cpp\n",
    "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "```\n",
    "\n",
    "```\n",
    "Example: 3 blocks Ã— 4 threads/block = 12 threads\n",
    "\n",
    "Block 0:  Thread 0  Thread 1  Thread 2  Thread 3\n",
    "          idx=0     idx=1     idx=2     idx=3\n",
    "          \n",
    "Block 1:  Thread 0  Thread 1  Thread 2  Thread 3  \n",
    "          idx=4     idx=5     idx=6     idx=7\n",
    "          \n",
    "Block 2:  Thread 0  Thread 1  Thread 2  Thread 3\n",
    "          idx=8     idx=9     idx=10    idx=11\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bfbd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile thread_indexing_1d.cu\n",
    "/**\n",
    " * Day 2: 1D Thread Indexing Demo\n",
    " * \n",
    " * Each thread prints its indices to understand the hierarchy.\n",
    " */\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void printIndices() {\n",
    "    // Calculate global thread index\n",
    "    int globalIdx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    printf(\"Block %d, Thread %d â†’ Global Index %d\\n\",\n",
    "           blockIdx.x, threadIdx.x, globalIdx);\n",
    "}\n",
    "\n",
    "__global__ void vectorAdd(float *a, float *b, float *c, int n) {\n",
    "    // The fundamental indexing pattern\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // ALWAYS check bounds!\n",
    "    if (idx < n) {\n",
    "        c[idx] = a[idx] + b[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== 1D Thread Indexing Demo ===\\n\\n\");\n",
    "    \n",
    "    // Demo 1: Print thread indices\n",
    "    printf(\"Launch: 3 blocks Ã— 4 threads/block\\n\");\n",
    "    printf(\"---------------------------------\\n\");\n",
    "    printIndices<<<3, 4>>>();\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Demo 2: Vector addition\n",
    "    printf(\"\\n=== Vector Addition ===\\n\");\n",
    "    int n = 10;\n",
    "    size_t size = n * sizeof(float);\n",
    "    \n",
    "    float h_a[] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\n",
    "    float h_b[] = {10, 20, 30, 40, 50, 60, 70, 80, 90, 100};\n",
    "    float h_c[10];\n",
    "    \n",
    "    float *d_a, *d_b, *d_c;\n",
    "    cudaMalloc(&d_a, size);\n",
    "    cudaMalloc(&d_b, size);\n",
    "    cudaMalloc(&d_c, size);\n",
    "    \n",
    "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Calculate grid size with ceiling division\n",
    "    int threadsPerBlock = 4;\n",
    "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
    "    \n",
    "    printf(\"Array size: %d\\n\", n);\n",
    "    printf(\"Threads per block: %d\\n\", threadsPerBlock);\n",
    "    printf(\"Blocks needed: %d\\n\", blocksPerGrid);\n",
    "    printf(\"Total threads: %d (some won't do work)\\n\\n\", blocksPerGrid * threadsPerBlock);\n",
    "    \n",
    "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    printf(\"Results: \");\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        printf(\"%.0f \", h_c[i]);\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "    \n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b68b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 thread_indexing_1d.cu -o thread_indexing_1d && ./thread_indexing_1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22833a",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "1. **Thread order is NOT guaranteed** - Blocks/threads may execute in any order\n",
    "2. **Bounds checking is essential** - When n=10 and total threads=12, threads 10 and 11 must NOT access array\n",
    "3. **Ceiling division formula**: `(n + blockSize - 1) / blockSize` ensures we cover all elements\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Grid-Stride Loops: Professional Pattern\n",
    "\n",
    "When array size >> thread count, use a **grid-stride loop**:\n",
    "\n",
    "```cpp\n",
    "// Each thread processes MULTIPLE elements\n",
    "for (int i = idx; i < n; i += gridDim.x * blockDim.x) {\n",
    "    // Process element i\n",
    "}\n",
    "```\n",
    "\n",
    "This pattern:\n",
    "- âœ… Works for ANY array size\n",
    "- âœ… Reuses threads efficiently  \n",
    "- âœ… Industry standard pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79222ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile grid_stride.cu\n",
    "/**\n",
    " * Grid-Stride Loop Pattern\n",
    " * \n",
    " * The professional way to handle arrays of ANY size.\n",
    " */\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Naive approach: 1 thread = 1 element (requires enough threads)\n",
    "__global__ void vectorAddNaive(float *a, float *b, float *c, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        c[idx] = a[idx] + b[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "// Grid-stride loop: each thread handles MULTIPLE elements\n",
    "__global__ void vectorAddGridStride(float *a, float *b, float *c, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;  // Total threads in grid\n",
    "    \n",
    "    // Each thread processes elements: idx, idx+stride, idx+2*stride, ...\n",
    "    for (int i = idx; i < n; i += stride) {\n",
    "        c[i] = a[i] + b[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int n = 1000000;  // 1 million elements\n",
    "    size_t size = n * sizeof(float);\n",
    "    \n",
    "    // Allocate and initialize\n",
    "    float *h_a = (float*)malloc(size);\n",
    "    float *h_b = (float*)malloc(size);\n",
    "    float *h_c = (float*)malloc(size);\n",
    "    \n",
    "    for (int i = 0; i < n; i++) {\n",
    "        h_a[i] = 1.0f;\n",
    "        h_b[i] = 2.0f;\n",
    "    }\n",
    "    \n",
    "    float *d_a, *d_b, *d_c;\n",
    "    cudaMalloc(&d_a, size);\n",
    "    cudaMalloc(&d_b, size);\n",
    "    cudaMalloc(&d_c, size);\n",
    "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Method 1: Naive (need many blocks)\n",
    "    int threadsPerBlock = 256;\n",
    "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
    "    \n",
    "    printf(\"=== Array size: %d elements ===\\n\\n\", n);\n",
    "    printf(\"Method 1: Naive (1 thread = 1 element)\\n\");\n",
    "    printf(\"  Blocks needed: %d\\n\", blocksPerGrid);\n",
    "    printf(\"  Total threads: %d\\n\\n\", blocksPerGrid * threadsPerBlock);\n",
    "    \n",
    "    vectorAddNaive<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Method 2: Grid-stride (can use fewer blocks!)\n",
    "    int limitedBlocks = 128;  // Use only 128 blocks\n",
    "    printf(\"Method 2: Grid-Stride Loop\\n\");\n",
    "    printf(\"  Blocks used: %d (much less!)\\n\", limitedBlocks);\n",
    "    printf(\"  Total threads: %d\\n\", limitedBlocks * threadsPerBlock);\n",
    "    printf(\"  Elements per thread: ~%d\\n\\n\", n / (limitedBlocks * threadsPerBlock));\n",
    "    \n",
    "    vectorAddGridStride<<<limitedBlocks, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Verify\n",
    "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
    "    bool correct = true;\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        if (h_c[i] != 3.0f) { correct = false; break; }\n",
    "    }\n",
    "    printf(\"Result: %s\\n\", correct ? \"âœ… CORRECT\" : \"âŒ WRONG\");\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
    "    free(h_a); free(h_b); free(h_c);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81d916",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 grid_stride.cu -o grid_stride && ./grid_stride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1032a277",
   "metadata": {},
   "source": [
    "### 2D Thread Indexing\n",
    "\n",
    "For 2D data like images and matrices, we use 2D grids and blocks with `dim3`:\n",
    "\n",
    "```cpp\n",
    "dim3 threadsPerBlock(16, 16);  // 16Ã—16 = 256 threads per block\n",
    "dim3 numBlocks((width + 15) / 16, (height + 15) / 16);\n",
    "\n",
    "myKernel<<<numBlocks, threadsPerBlock>>>(...);\n",
    "```\n",
    "\n",
    "Inside the kernel:\n",
    "```cpp\n",
    "int col = blockIdx.x * blockDim.x + threadIdx.x;  // X dimension\n",
    "int row = blockIdx.y * blockDim.y + threadIdx.y;  // Y dimension\n",
    "\n",
    "// 2D to 1D conversion for array access (row-major)\n",
    "int idx = row * width + col;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3138c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile indexing_2d.cu\n",
    "/**\n",
    " * 2D Thread Indexing for Matrices\n",
    " * \n",
    " * Demonstrates how to use dim3 for 2D grids and blocks.\n",
    " */\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define WIDTH 8\n",
    "#define HEIGHT 6\n",
    "\n",
    "// Print which thread handles which matrix element\n",
    "__global__ void print2DIndices() {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < HEIGHT && col < WIDTH) {\n",
    "        int linearIdx = row * WIDTH + col;\n",
    "        printf(\"Thread (%d,%d) in Block (%d,%d) â†’ Matrix[%d][%d] â†’ Linear %d\\n\",\n",
    "               threadIdx.x, threadIdx.y,\n",
    "               blockIdx.x, blockIdx.y,\n",
    "               row, col, linearIdx);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Matrix addition: C = A + B\n",
    "__global__ void matrixAdd(float *A, float *B, float *C, int width, int height) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    if (row < height && col < width) {\n",
    "        int idx = row * width + col;\n",
    "        C[idx] = A[idx] + B[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== 2D Thread Indexing Demo ===\\n\");\n",
    "    printf(\"Matrix size: %d x %d\\n\\n\", WIDTH, HEIGHT);\n",
    "    \n",
    "    // Use 4x4 blocks\n",
    "    dim3 threadsPerBlock(4, 4);\n",
    "    dim3 numBlocks((WIDTH + 3) / 4, (HEIGHT + 3) / 4);\n",
    "    \n",
    "    printf(\"Grid: %d x %d blocks\\n\", numBlocks.x, numBlocks.y);\n",
    "    printf(\"Block: %d x %d threads\\n\\n\", threadsPerBlock.x, threadsPerBlock.y);\n",
    "    \n",
    "    printf(\"Thread mapping (first 10 only):\\n\");\n",
    "    printf(\"----------------------------\\n\");\n",
    "    print2DIndices<<<numBlocks, threadsPerBlock>>>();\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Matrix addition example\n",
    "    printf(\"\\n=== Matrix Addition ===\\n\");\n",
    "    \n",
    "    int n = WIDTH * HEIGHT;\n",
    "    size_t size = n * sizeof(float);\n",
    "    \n",
    "    float *h_A = (float*)malloc(size);\n",
    "    float *h_B = (float*)malloc(size);\n",
    "    float *h_C = (float*)malloc(size);\n",
    "    \n",
    "    // Initialize: A[i][j] = i, B[i][j] = j\n",
    "    for (int i = 0; i < HEIGHT; i++) {\n",
    "        for (int j = 0; j < WIDTH; j++) {\n",
    "            h_A[i * WIDTH + j] = (float)i;\n",
    "            h_B[i * WIDTH + j] = (float)j;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    float *d_A, *d_B, *d_C;\n",
    "    cudaMalloc(&d_A, size);\n",
    "    cudaMalloc(&d_B, size);\n",
    "    cudaMalloc(&d_C, size);\n",
    "    \n",
    "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    matrixAdd<<<numBlocks, threadsPerBlock>>>(d_A, d_B, d_C, WIDTH, HEIGHT);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // Display result (C should be i + j at each position)\n",
    "    printf(\"Result C = A + B:\\n\");\n",
    "    for (int i = 0; i < HEIGHT; i++) {\n",
    "        for (int j = 0; j < WIDTH; j++) {\n",
    "            printf(\"%4.0f \", h_C[i * WIDTH + j]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
    "    free(h_A); free(h_B); free(h_C);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 indexing_2d.cu -o indexing_2d && ./indexing_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387c9dcd",
   "metadata": {},
   "source": [
    "### CUDA C++ Summary\n",
    "\n",
    "**1D Indexing Formula:**\n",
    "```cpp\n",
    "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "```\n",
    "\n",
    "**2D Indexing Formulas:**\n",
    "```cpp\n",
    "int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "int linearIdx = row * width + col;  // Row-major layout\n",
    "```\n",
    "\n",
    "**Grid-Stride Loop Pattern:**\n",
    "```cpp\n",
    "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "int stride = blockDim.x * gridDim.x;\n",
    "for (int i = idx; i < n; i += stride) {\n",
    "    // Process element i\n",
    "}\n",
    "```\n",
    "\n",
    "**Key Points:**\n",
    "- Always check bounds: `if (idx < n)` or `if (row < height && col < width)`\n",
    "- Use `dim3` for multi-dimensional configurations\n",
    "- Grid-stride loops handle any array size with any grid size\n",
    "- Thread indices are unique across the entire grid\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Python/Numba (Optional Comparison)\n",
    "\n",
    "The following sections demonstrate the same concepts using Python and Numba's CUDA JIT compiler. This is helpful for rapid prototyping but remember that production CUDA code is typically C++."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce586ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Colab Setup Cell - Run this first!\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"ğŸ”§ Running on Google Colab - Installing dependencies...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "    print(\"âœ… Setup complete!\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ’» Running locally - make sure you have: pip install numba numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e64bf6",
   "metadata": {},
   "source": [
    "# Day 2: Thread Indexing Mastery\n",
    "\n",
    "Yesterday you launched your first CUDA kernel. Today we'll master the art of **thread indexing** - how each thread knows which data element to process.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand 1D, 2D, and 3D thread indexing\n",
    "- Master the relationship between blocks, threads, and global indices\n",
    "- Implement grid-stride loops for handling any array size\n",
    "- Apply indexing to real 2D problems (matrices, images)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Thread Hierarchy Recap\n",
    "\n",
    "```\n",
    "                           GRID\n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚ Block   Block   Block   â”‚\n",
    "                â”‚ (0,0)   (1,0)   (2,0)   â”‚\n",
    "                â”‚                         â”‚\n",
    "                â”‚ Block   Block   Block   â”‚\n",
    "                â”‚ (0,1)   (1,1)   (2,1)   â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        \n",
    "                      Each Block:\n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚ Thread Thread Thread    â”‚\n",
    "                â”‚ (0,0)  (1,0)  (2,0)     â”‚\n",
    "                â”‚                         â”‚\n",
    "                â”‚ Thread Thread Thread    â”‚\n",
    "                â”‚ (0,1)  (1,1)  (2,1)     â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Built-in Variables (in Numba):**\n",
    "- `cuda.threadIdx.x/y/z` - Thread index within block\n",
    "- `cuda.blockIdx.x/y/z` - Block index within grid\n",
    "- `cuda.blockDim.x/y/z` - Threads per block\n",
    "- `cuda.gridDim.x/y/z` - Blocks in grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "\n",
    "print(\"CUDA available:\", cuda.is_available())\n",
    "print(\"Current device:\", cuda.get_current_device().name.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ed9210",
   "metadata": {},
   "source": [
    "## 2. 1D Indexing: The Foundation\n",
    "\n",
    "For 1D arrays, each thread needs a unique **global index**:\n",
    "\n",
    "```\n",
    "Global Index = blockIdx.x * blockDim.x + threadIdx.x\n",
    "\n",
    "Example: 3 blocks Ã— 4 threads/block = 12 threads\n",
    "\n",
    "Block 0:  Thread 0  Thread 1  Thread 2  Thread 3\n",
    "          idx=0     idx=1     idx=2     idx=3\n",
    "          \n",
    "Block 1:  Thread 0  Thread 1  Thread 2  Thread 3  \n",
    "          idx=4     idx=5     idx=6     idx=7\n",
    "          \n",
    "Block 2:  Thread 0  Thread 1  Thread 2  Thread 3\n",
    "          idx=8     idx=9     idx=10    idx=11\n",
    "```\n",
    "\n",
    "Let's visualize this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def print_1d_indices(output):\n",
    "    \"\"\"Each thread writes its indices to the output array\"\"\"\n",
    "    # Get indices manually\n",
    "    block_id = cuda.blockIdx.x\n",
    "    thread_id = cuda.threadIdx.x\n",
    "    block_size = cuda.blockDim.x\n",
    "    \n",
    "    # Calculate global index\n",
    "    global_idx = block_id * block_size + thread_id\n",
    "    \n",
    "    # Or use the convenient helper:\n",
    "    # global_idx = cuda.grid(1)\n",
    "    \n",
    "    if global_idx < output.shape[0]:\n",
    "        # Store: [global_idx, block_id, thread_id]\n",
    "        output[global_idx, 0] = global_idx\n",
    "        output[global_idx, 1] = block_id\n",
    "        output[global_idx, 2] = thread_id\n",
    "\n",
    "# Launch with 3 blocks Ã— 4 threads\n",
    "threads_per_block = 4\n",
    "blocks = 3\n",
    "total_threads = blocks * threads_per_block\n",
    "\n",
    "output = np.zeros((total_threads, 3), dtype=np.int32)\n",
    "output_d = cuda.to_device(output)\n",
    "\n",
    "print_1d_indices[blocks, threads_per_block](output_d)\n",
    "result = output_d.copy_to_host()\n",
    "\n",
    "print(\"1D Thread Indexing Visualization\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Configuration: {blocks} blocks Ã— {threads_per_block} threads/block\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Global Idx':^12} | {'Block ID':^10} | {'Thread ID':^10}\")\n",
    "print(\"-\" * 50)\n",
    "for row in result:\n",
    "    print(f\"{row[0]:^12} | {row[1]:^10} | {row[2]:^10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e9050",
   "metadata": {},
   "source": [
    "## 3. Boundary Checking: When Threads > Elements\n",
    "\n",
    "What happens when array size isn't a perfect multiple of block size?\n",
    "\n",
    "```\n",
    "Array size: 10 elements\n",
    "Block size: 4 threads\n",
    "Blocks needed: ceil(10/4) = 3\n",
    "Total threads: 3 Ã— 4 = 12\n",
    "\n",
    "Thread indices: 0  1  2  3  4  5  6  7  8  9  10  11\n",
    "Array elements: âœ“  âœ“  âœ“  âœ“  âœ“  âœ“  âœ“  âœ“  âœ“  âœ“   âœ—   âœ—\n",
    "                                               â†‘    â†‘\n",
    "                                          Out of bounds!\n",
    "```\n",
    "\n",
    "**Always add boundary checks!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6141a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def safe_square(input_arr, output_arr, n):\n",
    "    \"\"\"Square each element with proper boundary check\"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    # CRITICAL: Boundary check\n",
    "    if idx < n:\n",
    "        output_arr[idx] = input_arr[idx] ** 2\n",
    "\n",
    "# Array that's NOT a multiple of block size\n",
    "N = 1000\n",
    "a = np.arange(N, dtype=np.float32)\n",
    "b = np.zeros(N, dtype=np.float32)\n",
    "\n",
    "threads_per_block = 256\n",
    "blocks = math.ceil(N / threads_per_block)\n",
    "\n",
    "print(f\"Array size: {N}\")\n",
    "print(f\"Threads per block: {threads_per_block}\")\n",
    "print(f\"Blocks needed: {blocks}\")\n",
    "print(f\"Total threads: {blocks * threads_per_block}\")\n",
    "print(f\"Extra threads (idle): {blocks * threads_per_block - N}\")\n",
    "\n",
    "a_d = cuda.to_device(a)\n",
    "b_d = cuda.to_device(b)\n",
    "\n",
    "safe_square[blocks, threads_per_block](a_d, b_d, N)\n",
    "result = b_d.copy_to_host()\n",
    "\n",
    "# Verify\n",
    "expected = a ** 2\n",
    "print(f\"\\nâœ… Correct: {np.allclose(result, expected)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08549608",
   "metadata": {},
   "source": [
    "## 4. Grid-Stride Loops: The Professional Pattern\n",
    "\n",
    "What if your array has **billions** of elements but you can only launch millions of threads?\n",
    "\n",
    "**Grid-stride loop**: Each thread processes multiple elements, striding by the total grid size.\n",
    "\n",
    "```\n",
    "Array: [0][1][2][3][4][5][6][7][8][9][10][11]...\n",
    "\n",
    "Grid size: 4 threads\n",
    "\n",
    "Thread 0: processes indices 0, 4, 8, 12, ...\n",
    "Thread 1: processes indices 1, 5, 9, 13, ...\n",
    "Thread 2: processes indices 2, 6, 10, 14, ...\n",
    "Thread 3: processes indices 3, 7, 11, 15, ...\n",
    "```\n",
    "\n",
    "This pattern is **essential** for production code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def grid_stride_square(input_arr, output_arr, n):\n",
    "    \"\"\"Process arbitrary-sized arrays with grid-stride loop\"\"\"\n",
    "    # Starting index for this thread\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    # Total number of threads in the grid\n",
    "    stride = cuda.gridsize(1)  # = blockDim.x * gridDim.x\n",
    "    \n",
    "    # Grid-stride loop: each thread handles multiple elements\n",
    "    while idx < n:\n",
    "        output_arr[idx] = input_arr[idx] ** 2\n",
    "        idx += stride  # Jump to next element this thread handles\n",
    "\n",
    "# Huge array with limited grid\n",
    "N = 100_000_000  # 100 million elements!\n",
    "a = np.random.randn(N).astype(np.float32)\n",
    "b = np.zeros(N, dtype=np.float32)\n",
    "\n",
    "# Fixed, reasonable grid size\n",
    "threads_per_block = 256\n",
    "blocks = 256  # Only 256 blocks, but handles 100M elements!\n",
    "\n",
    "print(f\"Array size: {N:,}\")\n",
    "print(f\"Grid size: {blocks} blocks Ã— {threads_per_block} threads = {blocks * threads_per_block:,} threads\")\n",
    "print(f\"Elements per thread (average): {N / (blocks * threads_per_block):.1f}\")\n",
    "\n",
    "a_d = cuda.to_device(a)\n",
    "b_d = cuda.to_device(b)\n",
    "\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "grid_stride_square[blocks, threads_per_block](a_d, b_d, N)\n",
    "cuda.synchronize()\n",
    "elapsed = time.perf_counter() - start\n",
    "\n",
    "result = b_d.copy_to_host()\n",
    "print(f\"\\nâ±ï¸  Time: {elapsed*1000:.2f} ms\")\n",
    "print(f\"âœ… Correct: {np.allclose(result, a**2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaca503",
   "metadata": {},
   "source": [
    "## 5. 2D Indexing: Matrices and Images\n",
    "\n",
    "For 2D data (matrices, images), we use 2D thread blocks and grids:\n",
    "\n",
    "```\n",
    "Image (Height Ã— Width):\n",
    "â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”\n",
    "â”‚0,0â”‚0,1â”‚0,2â”‚0,3â”‚0,4â”‚  Row 0\n",
    "â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤\n",
    "â”‚1,0â”‚1,1â”‚1,2â”‚1,3â”‚1,4â”‚  Row 1\n",
    "â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤\n",
    "â”‚2,0â”‚2,1â”‚2,2â”‚2,3â”‚2,4â”‚  Row 2\n",
    "â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜\n",
    "\n",
    "Thread coordinates:\n",
    "  row = blockIdx.y * blockDim.y + threadIdx.y\n",
    "  col = blockIdx.x * blockDim.x + threadIdx.x\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matrix_double_2d(matrix, rows, cols):\n",
    "    \"\"\"Double each element using 2D indexing\"\"\"\n",
    "    # Get 2D thread coordinates\n",
    "    col, row = cuda.grid(2)  # Returns (x, y) = (col, row)\n",
    "    \n",
    "    # Boundary check for both dimensions\n",
    "    if row < rows and col < cols:\n",
    "        matrix[row, col] *= 2\n",
    "\n",
    "# Create a small matrix to visualize\n",
    "rows, cols = 6, 8\n",
    "matrix = np.arange(rows * cols, dtype=np.float32).reshape(rows, cols)\n",
    "\n",
    "print(\"Original matrix:\")\n",
    "print(matrix)\n",
    "print()\n",
    "\n",
    "# 2D block configuration\n",
    "threads_per_block_2d = (4, 4)  # 4Ã—4 = 16 threads per block\n",
    "blocks_per_grid_x = math.ceil(cols / threads_per_block_2d[0])\n",
    "blocks_per_grid_y = math.ceil(rows / threads_per_block_2d[1])\n",
    "blocks_per_grid_2d = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "print(f\"Block size: {threads_per_block_2d}\")\n",
    "print(f\"Grid size: {blocks_per_grid_2d}\")\n",
    "\n",
    "matrix_d = cuda.to_device(matrix)\n",
    "matrix_double_2d[blocks_per_grid_2d, threads_per_block_2d](matrix_d, rows, cols)\n",
    "result = matrix_d.copy_to_host()\n",
    "\n",
    "print(\"\\nDoubled matrix:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f2cc0",
   "metadata": {},
   "source": [
    "## 6. Practical Example: Image Processing (Grayscale)\n",
    "\n",
    "Let's apply 2D indexing to convert an RGB image to grayscale.\n",
    "\n",
    "Grayscale formula: `Y = 0.299*R + 0.587*G + 0.114*B`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def rgb_to_grayscale(rgb_image, gray_image, height, width):\n",
    "    \"\"\"Convert RGB image to grayscale using 2D indexing\"\"\"\n",
    "    col, row = cuda.grid(2)\n",
    "    \n",
    "    if row < height and col < width:\n",
    "        # RGB channels\n",
    "        r = rgb_image[row, col, 0]\n",
    "        g = rgb_image[row, col, 1]\n",
    "        b = rgb_image[row, col, 2]\n",
    "        \n",
    "        # Weighted sum (human perception weighting)\n",
    "        gray = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "        \n",
    "        gray_image[row, col] = gray\n",
    "\n",
    "# Create a synthetic RGB image (like a gradient)\n",
    "height, width = 1080, 1920  # Full HD\n",
    "rgb_image = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8).astype(np.float32)\n",
    "\n",
    "gray_image = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "# Configure 2D grid\n",
    "threads_per_block = (16, 16)  # 256 threads per block\n",
    "blocks_x = math.ceil(width / threads_per_block[0])\n",
    "blocks_y = math.ceil(height / threads_per_block[1])\n",
    "blocks_per_grid = (blocks_x, blocks_y)\n",
    "\n",
    "print(f\"Image size: {height} Ã— {width} ({height * width:,} pixels)\")\n",
    "print(f\"Thread block: {threads_per_block}\")\n",
    "print(f\"Grid: {blocks_per_grid}\")\n",
    "print(f\"Total threads: {blocks_x * threads_per_block[0]} Ã— {blocks_y * threads_per_block[1]}\")\n",
    "\n",
    "# Run on GPU\n",
    "rgb_d = cuda.to_device(rgb_image)\n",
    "gray_d = cuda.to_device(gray_image)\n",
    "\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "rgb_to_grayscale[blocks_per_grid, threads_per_block](rgb_d, gray_d, height, width)\n",
    "cuda.synchronize()\n",
    "gpu_time = time.perf_counter() - start\n",
    "\n",
    "gray_result = gray_d.copy_to_host()\n",
    "\n",
    "# Compare with NumPy (CPU)\n",
    "start = time.perf_counter()\n",
    "gray_cpu = 0.299 * rgb_image[:,:,0] + 0.587 * rgb_image[:,:,1] + 0.114 * rgb_image[:,:,2]\n",
    "cpu_time = time.perf_counter() - start\n",
    "\n",
    "print(f\"\\nâ±ï¸  GPU time: {gpu_time*1000:.3f} ms\")\n",
    "print(f\"â±ï¸  CPU time: {cpu_time*1000:.3f} ms\")\n",
    "print(f\"ğŸš€ Speedup: {cpu_time/gpu_time:.2f}x\")\n",
    "print(f\"âœ… Correct: {np.allclose(gray_result, gray_cpu, atol=1e-5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f05a7c",
   "metadata": {},
   "source": [
    "## ğŸ¯ Exercises\n",
    "\n",
    "### Exercise 1: Manual Index Calculation\n",
    "Implement 1D indexing WITHOUT using `cuda.grid()` - calculate manually using `blockIdx`, `blockDim`, `threadIdx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Exercise 1: Manual indexing\n",
    "@cuda.jit\n",
    "def manual_index_add(a, b, c):\n",
    "    \"\"\"Add arrays using MANUAL index calculation\"\"\"\n",
    "    # TODO: Calculate global index manually\n",
    "    # idx = blockIdx.x * blockDim.x + threadIdx.x\n",
    "    idx = 0  # FIX THIS\n",
    "    \n",
    "    if idx < c.size:\n",
    "        c[idx] = a[idx] + b[idx]\n",
    "\n",
    "# Test your implementation\n",
    "# N = 1000\n",
    "# a = np.random.randn(N).astype(np.float32)\n",
    "# b = np.random.randn(N).astype(np.float32)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefcfb60",
   "metadata": {},
   "source": [
    "### Exercise 2: 2D Grid-Stride Loop\n",
    "Implement a 2D grid-stride loop for processing very large images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29dc6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Exercise 2: 2D Grid-Stride Loop\n",
    "@cuda.jit\n",
    "def grid_stride_2d(matrix, height, width):\n",
    "    \"\"\"Process large matrix with 2D grid-stride loop\"\"\"\n",
    "    # Starting position\n",
    "    start_col, start_row = cuda.grid(2)\n",
    "    \n",
    "    # Stride (grid size in each dimension)\n",
    "    stride_col, stride_row = cuda.gridsize(2)\n",
    "    \n",
    "    # TODO: Implement 2D grid-stride loop\n",
    "    # Hint: Use nested while loops\n",
    "    # row = start_row\n",
    "    # while row < height:\n",
    "    #     col = start_col\n",
    "    #     while col < width:\n",
    "    #         # process matrix[row, col]\n",
    "    #         col += stride_col\n",
    "    #     row += stride_row\n",
    "    pass\n",
    "\n",
    "# Test with a huge matrix\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca86ad64",
   "metadata": {},
   "source": [
    "### Exercise 3: Image Negative\n",
    "Create a kernel that inverts an image (negative): `output[i,j] = 255 - input[i,j]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ac798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Exercise 3: Image Negative\n",
    "@cuda.jit\n",
    "def image_negative(input_img, output_img, height, width):\n",
    "    \"\"\"Invert image: output = 255 - input\"\"\"\n",
    "    # TODO: Implement using 2D indexing\n",
    "    pass\n",
    "\n",
    "# Test your implementation\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a806a8ff",
   "metadata": {},
   "source": [
    "## ğŸ“ Key Takeaways\n",
    "\n",
    "### Today You Learned:\n",
    "\n",
    "1. **1D Indexing Formula**:\n",
    "   ```\n",
    "   global_idx = blockIdx.x * blockDim.x + threadIdx.x\n",
    "   # Or simply: cuda.grid(1)\n",
    "   ```\n",
    "\n",
    "2. **2D Indexing Formula**:\n",
    "   ```\n",
    "   col, row = cuda.grid(2)\n",
    "   # Manually: \n",
    "   # row = blockIdx.y * blockDim.y + threadIdx.y\n",
    "   # col = blockIdx.x * blockDim.x + threadIdx.x\n",
    "   ```\n",
    "\n",
    "3. **Always check boundaries**: `if idx < n:`\n",
    "\n",
    "4. **Grid-stride loops** handle any array size with fixed grid:\n",
    "   ```python\n",
    "   idx = cuda.grid(1)\n",
    "   stride = cuda.gridsize(1)\n",
    "   while idx < n:\n",
    "       # process element\n",
    "       idx += stride\n",
    "   ```\n",
    "\n",
    "5. **Common block sizes**:\n",
    "   - 1D: 256 or 512 threads\n",
    "   - 2D: (16, 16) or (32, 32) threads\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š Next Up: Day 3 - Memory Fundamentals\n",
    "- cudaMalloc vs cudaMallocManaged\n",
    "- Pinned vs pageable memory\n",
    "- Memory transfer optimization\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”— Resources\n",
    "- [Thread Hierarchy - Programming Guide](../../cuda-programming-guide/01-introduction/programming-model.md)\n",
    "- [Quick Reference](../../notes/cuda-quick-reference.md)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "431078fb",
   "metadata": {},
   "source": [
    "## Part 1: CUDA C++ (Primary)\n",
    "\n",
    "### GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426df9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.bandwidth.total --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3c7939",
   "metadata": {},
   "source": [
    "### What is Memory Coalescing?\n",
    "\n",
    "**Memory coalescing** is when the GPU combines multiple memory accesses from threads in a warp into fewer memory transactions.\n",
    "\n",
    "```\n",
    "WARP (32 threads)\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ T0  T1  T2  T3  T4  T5  ... T31                              â”‚\n",
    "â”‚  â†“   â†“   â†“   â†“   â†“   â†“       â†“                               â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "COALESCED ACCESS (1 transaction for 128 bytes):\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ data[0] data[1] data[2] data[3] ... data[31]                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "  Thread 0 â†’ data[0], Thread 1 â†’ data[1], etc.\n",
    "\n",
    "STRIDED ACCESS (32 separate transactions!):\n",
    "â”Œâ”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”\n",
    "â”‚d[0]â”‚     â”‚d[32]â”‚    â”‚d[64]â”‚  ...\n",
    "â””â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”˜\n",
    "  T0 â†‘       T1 â†‘       T2 â†‘\n",
    "```\n",
    "\n",
    "**Key Rule:** Consecutive threads should access consecutive memory addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile coalescing_demo.cu\n",
    "/**\n",
    " * Memory Coalescing Demo\n",
    " * \n",
    " * Compare coalesced vs strided memory access patterns.\n",
    " */\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define N (1 << 24)  // 16 million elements\n",
    "#define BLOCK_SIZE 256\n",
    "#define ITERATIONS 100\n",
    "\n",
    "// âœ… COALESCED: Thread i accesses element i\n",
    "__global__ void coalescedAccess(float *input, float *output, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        output[idx] = input[idx] * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "// âŒ STRIDED: Thread i accesses element i*stride (poor coalescing)\n",
    "__global__ void stridedAccess(float *input, float *output, int n, int stride) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int strided_idx = (idx * stride) % n;\n",
    "    if (idx < n) {\n",
    "        output[idx] = input[strided_idx] * 2.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "float benchmark(void (*kernel)(float*, float*, int), float *d_in, float *d_out, int n) {\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    int blocks = (n + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "    \n",
    "    // Warmup\n",
    "    kernel<<<blocks, BLOCK_SIZE>>>(d_in, d_out, n);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < ITERATIONS; i++) {\n",
    "        kernel<<<blocks, BLOCK_SIZE>>>(d_in, d_out, n);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return ms / ITERATIONS;\n",
    "}\n",
    "\n",
    "float benchmarkStrided(float *d_in, float *d_out, int n, int stride) {\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    int blocks = (n + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "    \n",
    "    // Warmup\n",
    "    stridedAccess<<<blocks, BLOCK_SIZE>>>(d_in, d_out, n, stride);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < ITERATIONS; i++) {\n",
    "        stridedAccess<<<blocks, BLOCK_SIZE>>>(d_in, d_out, n, stride);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    \n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return ms / ITERATIONS;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Memory Coalescing Benchmark ===\\n\");\n",
    "    printf(\"Array size: %d elements (%.2f MB)\\n\\n\", N, N * sizeof(float) / (1024.0 * 1024.0));\n",
    "    \n",
    "    float *d_input, *d_output;\n",
    "    cudaMalloc(&d_input, N * sizeof(float));\n",
    "    cudaMalloc(&d_output, N * sizeof(float));\n",
    "    \n",
    "    // Initialize\n",
    "    float *h_input = (float*)malloc(N * sizeof(float));\n",
    "    for (int i = 0; i < N; i++) h_input[i] = 1.0f;\n",
    "    cudaMemcpy(d_input, h_input, N * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Benchmark coalesced\n",
    "    float coalesced_time = benchmark(coalescedAccess, d_input, d_output, N);\n",
    "    float coalesced_bw = (2.0f * N * sizeof(float)) / (coalesced_time * 1e6);  // GB/s\n",
    "    \n",
    "    printf(\"âœ… Coalesced Access:\\n\");\n",
    "    printf(\"   Time: %.3f ms\\n\", coalesced_time);\n",
    "    printf(\"   Bandwidth: %.2f GB/s\\n\\n\", coalesced_bw);\n",
    "    \n",
    "    // Benchmark strided with different strides\n",
    "    int strides[] = {2, 4, 8, 16, 32};\n",
    "    for (int s = 0; s < 5; s++) {\n",
    "        int stride = strides[s];\n",
    "        float strided_time = benchmarkStrided(d_input, d_output, N, stride);\n",
    "        float strided_bw = (2.0f * N * sizeof(float)) / (strided_time * 1e6);\n",
    "        float slowdown = strided_time / coalesced_time;\n",
    "        \n",
    "        printf(\"âŒ Stride=%d Access:\\n\", stride);\n",
    "        printf(\"   Time: %.3f ms (%.1fx slower)\\n\", strided_time, slowdown);\n",
    "        printf(\"   Bandwidth: %.2f GB/s\\n\\n\", strided_bw);\n",
    "    }\n",
    "    \n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output);\n",
    "    free(h_input);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecd9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -O3 coalescing_demo.cu -o coalescing_demo && ./coalescing_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2187b779",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "1. **Coalesced access** achieves near-peak memory bandwidth\n",
    "2. **Stride-2** roughly halves the effective bandwidth\n",
    "3. **Stride-32** (warp size) is particularly bad - each thread hits a different cache line\n",
    "\n",
    "### Array of Structures vs Structure of Arrays\n",
    "\n",
    "A common coalescing problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23593a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile aos_vs_soa.cu\n",
    "/**\n",
    " * Array of Structures (AoS) vs Structure of Arrays (SoA)\n",
    " * \n",
    " * SoA is almost always better for GPU memory access.\n",
    " */\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define N (1 << 22)  // 4 million particles\n",
    "#define BLOCK_SIZE 256\n",
    "#define ITERATIONS 100\n",
    "\n",
    "// âŒ Array of Structures (AoS) - Poor coalescing\n",
    "struct ParticleAoS {\n",
    "    float x, y, z;    // Position\n",
    "    float vx, vy, vz; // Velocity\n",
    "};\n",
    "\n",
    "// âœ… Structure of Arrays (SoA) - Good coalescing\n",
    "struct ParticlesSoA {\n",
    "    float *x, *y, *z;\n",
    "    float *vx, *vy, *vz;\n",
    "};\n",
    "\n",
    "__global__ void updateAoS(ParticleAoS *particles, float dt, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        // Strided access: each thread reads 6 floats spread apart\n",
    "        particles[idx].x += particles[idx].vx * dt;\n",
    "        particles[idx].y += particles[idx].vy * dt;\n",
    "        particles[idx].z += particles[idx].vz * dt;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void updateSoA(float *x, float *y, float *z,\n",
    "                          float *vx, float *vy, float *vz,\n",
    "                          float dt, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        // Coalesced access: consecutive threads read consecutive floats\n",
    "        x[idx] += vx[idx] * dt;\n",
    "        y[idx] += vy[idx] * dt;\n",
    "        z[idx] += vz[idx] * dt;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== AoS vs SoA Benchmark ===\\n\");\n",
    "    printf(\"Particles: %d\\n\\n\", N);\n",
    "    \n",
    "    // Allocate AoS\n",
    "    ParticleAoS *d_aos;\n",
    "    cudaMalloc(&d_aos, N * sizeof(ParticleAoS));\n",
    "    \n",
    "    // Allocate SoA\n",
    "    float *d_x, *d_y, *d_z, *d_vx, *d_vy, *d_vz;\n",
    "    cudaMalloc(&d_x, N * sizeof(float));\n",
    "    cudaMalloc(&d_y, N * sizeof(float));\n",
    "    cudaMalloc(&d_z, N * sizeof(float));\n",
    "    cudaMalloc(&d_vx, N * sizeof(float));\n",
    "    cudaMalloc(&d_vy, N * sizeof(float));\n",
    "    cudaMalloc(&d_vz, N * sizeof(float));\n",
    "    \n",
    "    int blocks = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "    float dt = 0.01f;\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    // Benchmark AoS\n",
    "    updateAoS<<<blocks, BLOCK_SIZE>>>(d_aos, dt, N);  // Warmup\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < ITERATIONS; i++) {\n",
    "        updateAoS<<<blocks, BLOCK_SIZE>>>(d_aos, dt, N);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float aos_time;\n",
    "    cudaEventElapsedTime(&aos_time, start, stop);\n",
    "    aos_time /= ITERATIONS;\n",
    "    \n",
    "    // Benchmark SoA\n",
    "    updateSoA<<<blocks, BLOCK_SIZE>>>(d_x, d_y, d_z, d_vx, d_vy, d_vz, dt, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < ITERATIONS; i++) {\n",
    "        updateSoA<<<blocks, BLOCK_SIZE>>>(d_x, d_y, d_z, d_vx, d_vy, d_vz, dt, N);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float soa_time;\n",
    "    cudaEventElapsedTime(&soa_time, start, stop);\n",
    "    soa_time /= ITERATIONS;\n",
    "    \n",
    "    printf(\"âŒ Array of Structures (AoS): %.3f ms\\n\", aos_time);\n",
    "    printf(\"âœ… Structure of Arrays (SoA): %.3f ms\\n\", soa_time);\n",
    "    printf(\"\\nSpeedup: %.2fx\\n\", aos_time / soa_time);\n",
    "    \n",
    "    // Cleanup\n",
    "    cudaFree(d_aos);\n",
    "    cudaFree(d_x); cudaFree(d_y); cudaFree(d_z);\n",
    "    cudaFree(d_vx); cudaFree(d_vy); cudaFree(d_vz);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83aca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -O3 aos_vs_soa.cu -o aos_vs_soa && ./aos_vs_soa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae218ea6",
   "metadata": {},
   "source": [
    "### Matrix Transpose - A Classic Coalescing Problem\n",
    "\n",
    "Matrix transpose is challenging because:\n",
    "- Reading rows is coalesced\n",
    "- Writing to columns is strided (or vice versa)\n",
    "\n",
    "We'll solve this with shared memory in Day 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8112f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile transpose_naive.cu\n",
    "/**\n",
    " * Naive Matrix Transpose - Shows the coalescing problem\n",
    " */\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define WIDTH 4096\n",
    "#define HEIGHT 4096\n",
    "#define TILE_DIM 32\n",
    "#define ITERATIONS 100\n",
    "\n",
    "// Copy kernel (coalesced read AND write) - for comparison\n",
    "__global__ void copy(float *out, float *in, int width, int height) {\n",
    "    int x = blockIdx.x * TILE_DIM + threadIdx.x;\n",
    "    int y = blockIdx.y * TILE_DIM + threadIdx.y;\n",
    "    \n",
    "    if (x < width && y < height) {\n",
    "        int idx = y * width + x;\n",
    "        out[idx] = in[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "// Naive transpose (coalesced read, strided write)\n",
    "__global__ void transposeNaive(float *out, float *in, int width, int height) {\n",
    "    int x = blockIdx.x * TILE_DIM + threadIdx.x;\n",
    "    int y = blockIdx.y * TILE_DIM + threadIdx.y;\n",
    "    \n",
    "    if (x < width && y < height) {\n",
    "        int in_idx = y * width + x;      // Row-major read (coalesced)\n",
    "        int out_idx = x * height + y;    // Column-major write (strided!)\n",
    "        out[out_idx] = in[in_idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"=== Matrix Transpose Benchmark ===\\n\");\n",
    "    printf(\"Matrix: %d x %d\\n\\n\", WIDTH, HEIGHT);\n",
    "    \n",
    "    size_t size = WIDTH * HEIGHT * sizeof(float);\n",
    "    \n",
    "    float *d_in, *d_out;\n",
    "    cudaMalloc(&d_in, size);\n",
    "    cudaMalloc(&d_out, size);\n",
    "    \n",
    "    dim3 block(TILE_DIM, TILE_DIM);\n",
    "    dim3 grid((WIDTH + TILE_DIM - 1) / TILE_DIM, (HEIGHT + TILE_DIM - 1) / TILE_DIM);\n",
    "    \n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    \n",
    "    // Benchmark copy\n",
    "    copy<<<grid, block>>>(d_out, d_in, WIDTH, HEIGHT);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < ITERATIONS; i++) {\n",
    "        copy<<<grid, block>>>(d_out, d_in, WIDTH, HEIGHT);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float copy_time;\n",
    "    cudaEventElapsedTime(&copy_time, start, stop);\n",
    "    copy_time /= ITERATIONS;\n",
    "    float copy_bw = 2.0f * size / (copy_time * 1e6);\n",
    "    \n",
    "    // Benchmark naive transpose\n",
    "    transposeNaive<<<grid, block>>>(d_out, d_in, WIDTH, HEIGHT);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    cudaEventRecord(start);\n",
    "    for (int i = 0; i < ITERATIONS; i++) {\n",
    "        transposeNaive<<<grid, block>>>(d_out, d_in, WIDTH, HEIGHT);\n",
    "    }\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    \n",
    "    float transpose_time;\n",
    "    cudaEventElapsedTime(&transpose_time, start, stop);\n",
    "    transpose_time /= ITERATIONS;\n",
    "    float transpose_bw = 2.0f * size / (transpose_time * 1e6);\n",
    "    \n",
    "    printf(\"Copy (coalesced R+W):     %.3f ms, %.2f GB/s\\n\", copy_time, copy_bw);\n",
    "    printf(\"Naive Transpose (strided): %.3f ms, %.2f GB/s\\n\", transpose_time, transpose_bw);\n",
    "    printf(\"\\nTranspose is %.2fx slower due to uncoalesced writes\\n\", transpose_time / copy_time);\n",
    "    printf(\"\\nğŸ’¡ We'll fix this with shared memory tomorrow!\\n\");\n",
    "    \n",
    "    cudaFree(d_in);\n",
    "    cudaFree(d_out);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a4e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 -O3 transpose_naive.cu -o transpose_naive && ./transpose_naive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305a30a",
   "metadata": {},
   "source": [
    "### Memory Coalescing Summary\n",
    "\n",
    "| Pattern | Description | Performance |\n",
    "|---------|-------------|-------------|\n",
    "| Coalesced | Thread i accesses data[i] | âœ… Best |\n",
    "| Strided | Thread i accesses data[i*stride] | âŒ Poor |\n",
    "| AoS | struct { x,y,z } particles[N] | âŒ Poor |\n",
    "| SoA | float x[N], y[N], z[N] | âœ… Best |\n",
    "\n",
    "**Key Rules:**\n",
    "1. Consecutive threads should access consecutive addresses\n",
    "2. Prefer Structure of Arrays (SoA) over Array of Structures (AoS)\n",
    "3. When one direction must be strided, use shared memory as a staging area\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Python/Numba (Optional)\n",
    "\n",
    "The same concepts apply in Python/Numba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f2b620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for Numba\n",
    "import subprocess, sys\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numba\"])\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "from numba import cuda\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(f\"CUDA Device: {cuda.get_current_device().name.decode()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b60b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coalesced vs Strided in Python\n",
    "\n",
    "@cuda.jit\n",
    "def coalesced_kernel(input_arr, output_arr):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < input_arr.size:\n",
    "        output_arr[idx] = input_arr[idx] * 2.0\n",
    "\n",
    "@cuda.jit\n",
    "def strided_kernel(input_arr, output_arr, stride):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < output_arr.size:\n",
    "        strided_idx = (idx * stride) % input_arr.size\n",
    "        output_arr[idx] = input_arr[strided_idx] * 2.0\n",
    "\n",
    "# Test\n",
    "N = 1 << 24\n",
    "input_arr = cuda.to_device(np.ones(N, dtype=np.float32))\n",
    "output_arr = cuda.device_array(N, dtype=np.float32)\n",
    "\n",
    "threads = 256\n",
    "blocks = (N + threads - 1) // threads\n",
    "\n",
    "# Warmup and time coalesced\n",
    "coalesced_kernel[blocks, threads](input_arr, output_arr)\n",
    "cuda.synchronize()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(100):\n",
    "    coalesced_kernel[blocks, threads](input_arr, output_arr)\n",
    "cuda.synchronize()\n",
    "coalesced_time = (time.perf_counter() - start) / 100 * 1000\n",
    "\n",
    "print(f\"âœ… Coalesced: {coalesced_time:.3f} ms\")\n",
    "\n",
    "# Time strided\n",
    "strided_kernel[blocks, threads](input_arr, output_arr, 32)\n",
    "cuda.synchronize()\n",
    "\n",
    "start = time.perf_counter()\n",
    "for _ in range(100):\n",
    "    strided_kernel[blocks, threads](input_arr, output_arr, 32)\n",
    "cuda.synchronize()\n",
    "strided_time = (time.perf_counter() - start) / 100 * 1000\n",
    "\n",
    "print(f\"âŒ Strided (stride=32): {strided_time:.3f} ms\")\n",
    "print(f\"\\nStrided is {strided_time/coalesced_time:.1f}x slower\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
